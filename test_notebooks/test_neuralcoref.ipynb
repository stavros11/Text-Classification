{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "coref = neuralcoref.NeuralCoref(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(coref, name='neuralcoref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My sister has a dog. My sister loves a dog.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"My sister has a dog. She loves him.\")\n",
    "print(doc._.coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1166689, 6)\n",
      "(1166096, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/stavros/DATA/AirbnbReviews\"\n",
    "\n",
    "area = \"nyc\"\n",
    "area_dir = os.path.join(data_dir, area)\n",
    "\n",
    "data = pd.read_csv(os.path.join(area_dir, \"reviews.csv.gz\"))\n",
    "print(data.shape)\n",
    "\n",
    "clean_data = data[pd.notnull(data.comments)]\n",
    "print(clean_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 / 1000 found.\n",
      "201 / 1000 found.\n",
      "301 / 1000 found.\n",
      "401 / 1000 found.\n",
      "501 / 1000 found.\n",
      "601 / 1000 found.\n",
      "701 / 1000 found.\n",
      "801 / 1000 found.\n",
      "901 / 1000 found.\n",
      "1001 / 1000 found.\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "from utils import dependencies\n",
    "from utils import preprocessing\n",
    "\n",
    "\n",
    "normalizer = preprocessing.CorpusNormalizer(\n",
    "                 html_stripping=False, contraction_expansion=True,\n",
    "                 accented_char_removal=True, text_lower_case=True,\n",
    "                 text_lemmatization=False, special_char_removal=False,\n",
    "                 stopword_removal=False, remove_digits=False)\n",
    "\n",
    "n_samples = 500\n",
    "n_message = 100\n",
    "\n",
    "ids = np.arange(len(clean_data))\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "sampled_columns = list(clean_data.columns) + [\"processed_comments\", \"coref_resolved\"]\n",
    "sampled_data = pd.DataFrame(index=range(n_samples), columns=sampled_columns)\n",
    "i, ic = 0, 0\n",
    "while ic < n_samples:\n",
    "    data_row = clean_data.iloc[ids[i]]\n",
    "    review = data_row[\"comments\"]\n",
    "    i += 1\n",
    "    if (not isinstance(review, str)) or len(review) < 5:\n",
    "        # Skip invalid reviews\n",
    "        continue\n",
    "    if \"canceled\" in review:\n",
    "        # If it is an automated cancellation review then skip\n",
    "        continue\n",
    "    try:\n",
    "        review_lang = langdetect.detect(review)\n",
    "    except:\n",
    "        continue\n",
    "    if review_lang != \"en\":\n",
    "        continue\n",
    "        \n",
    "    processed_review = normalizer([review])[0]\n",
    "    sampled_data.iloc[ic] = data_row\n",
    "    sampled_data.iloc[ic][\"processed_comments\"] = processed_review\n",
    "    sampled_data.iloc[ic][\"coref_resolved\"] = nlp(processed_review)\n",
    "    \n",
    "    ic += 1\n",
    "        \n",
    "    if ic % n_message == 0:\n",
    "        print(\"{} / {} found.\".format(ic + 1, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments',\n",
       "       'processed_comments', 'coref_resolved', 'entities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "sampled_data[\"entities\"] = sampled_data[\"comments\"].map(lambda text: nlp(text).ents)\n",
    "\n",
    "sampled_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We had a wonderful weekend at Martyâ€™s place ! It was even better than we expected . Will definitely be coming back again someday :)\n",
      "\n",
      "(Marty,)\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.randint(0, len(sampled_data))\n",
    "\n",
    "print(sampled_data.iloc[ind].comments)\n",
    "print()\n",
    "print(sampled_data.iloc[ind].entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We had a fantastic stay at Alvaro's apartment. It was clean and quiet during the nighttime.  The neighborhood is great and there are 2 subways within 10 min walking distance (Website hidden by Airbnb) would book the room anytime again!\n",
      "(Alvaro, 2, 10, Airbnb)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"We had a fantastic stay at Alvaro's apartment. It was clean and quiet during the nighttime.  The neighborhood is great and there are 2 subways within 10 min walking distance (Website hidden by Airbnb) would book the room anytime again!\"\n",
    "print(sentence)\n",
    "\n",
    "doc = nlp(sentence)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPE'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[-1].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

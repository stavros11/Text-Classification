{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams[\"font.size\"] = 26\n",
    "\n",
    "data_dir = \"/home/stavros/DATA/AirbnbReviews\"\n",
    "#data_dir = \"D:/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"nyc\"\n",
    "area_dir = os.path.join(data_dir, area)\n",
    "\n",
    "reviews = pd.read_csv(os.path.join(area_dir, \"nyc_reviews_20000samplesnostopwords.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n",
      "Index(['Unnamed: 0', 'listing_id', 'id', 'date', 'reviewer_id',\n",
      "       'reviewer_name', 'comments', 'normalized_comments'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(reviews.shape)\n",
    "print(reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19820, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reviews = reviews[pd.notnull(reviews.normalized_comments)]\n",
    "clean_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "docs = [tokenizer.tokenize(review) for review in clean_reviews.normalized_comments]\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary and bag-of-words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25849\n",
      "3639\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "print(len(dictionary))\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.1)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply `gensim` LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = models.LdaModel(corpus=corpus, id2word=dictionary.id2token, num_topics=3, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.046*\"de\" + 0.032*\"la\" + 0.023*\"et\" + 0.020*\"en\" + 0.019*\"un\" + 0.017*\"est\" + 0.017*\"tre\" + 0.016*\"que\" + 0.016*\"el\" + 0.015*\"muy\"'),\n",
       " (1,\n",
       "  '0.036*\"und\" + 0.027*\"die\" + 0.023*\"ist\" + 0.021*\"cancel\" + 0.021*\"reservation\" + 0.021*\"arrival\" + 0.020*\"day\" + 0.019*\"sehr\" + 0.018*\"posting\" + 0.017*\"automate\"'),\n",
       " (2,\n",
       "  '0.008*\"home\" + 0.007*\"also\" + 0.007*\"check\" + 0.007*\"bed\" + 0.007*\"neighborhood\" + 0.007*\"space\" + 0.006*\"area\" + 0.006*\"like\" + 0.006*\"go\" + 0.006*\"helpful\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
